
| 分词方法    | 特点                  | 时间 | 模型        |
|------------|----------------------|-------------|----------------|
| BPE        | 采用合并规则，可以适应未知词 | 2016年     | GPT-2、RoBERTa |
| WordPiece  | 采用逐步拆分的方法，可以适应未知词 | 2016年     | BERT           |
| Unigram LM | 采用无序语言模型，训练速度快  | 2018年     | XLM            |
| SentencePiece | 采用汉字、字符和子词三种分词方式，支持多语言 | 2018年 | T5、ALBERT     |

### word level
### char level
### subword level

# Byte-Pair Encoding(BPE)

# Byte-level BPE 

# WordPiece 

# Unigram LM 篇

# SentencePiece 

# Transformer Tokenizer


# 参考文献
llm_interview_note/02.大语言模型基础/4.tokenize分词/4.tokenize分词.md[https://github.com/wdndev/llm_interview_note/blob/main/02.%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%9F%BA%E7%A1%80/4.tokenize%E5%88%86%E8%AF%8D/4.tokenize%E5%88%86%E8%AF%8D.md]
