# Model Quantization

![image](https://github.com/hinswhale/AI-Learning/assets/22999866/785ee7cb-5f90-4b12-9879-fdaa2a1caeac)


# 量化 Model Quantization

概念：`量化`，`反量化`，`量化误差`

将连续的输入映射到离散的输出集合。

## **量化映射**

- Fixed Point Approximation
    
    定点近似主要是缩小浮点表示中的指数和小数部分的位宽，不需要额外的量化参数，也没有反量化过程，实现相对简单，但是在数值较大时，直接定点近似会带来较大的精度损失。
    
  ![image](https://github.com/hinswhale/AI-Learning/assets/22999866/9634539f-04fc-4454-b84d-2cf5aa44e714)

    
- Range Based Approximation
    
    基于范围的近似，则是先统计待量化数据的分布，然后进行整体的缩放和偏移，再映射到量化空间，精度相对更高，但需要额外存储量化参数(如缩放系数、偏移等)，并且计算时需要先反量化，比定点近似更复杂。根据映射方式的不同，又可分为线性映射和非线性映射：
    

### **`量化`**

**`量化公式`**：$x_q = \text{round}\left(\frac{x}{\text{S}}\right) + \text{Z}$  (将浮点数向量 𝒙 转化为量化值 𝒙𝒒)

𝑆 表示缩放因子，用于确定裁剪范围

𝑍 表示零点因子，用于确定对称或非对称量化，也就是 fp32 中的零在量化 tensor 中的值。

round(·)表示将缩放后的浮点值映射为近似整数的取整操作。

### **`反量化`**

**`反量化`**（Dequantization）：从量化值中恢复原始值

$\tilde{x} = (x_q - \text{Z}) \times \text{S}$

`量化误差`是原始值 𝒙 和恢复值$\tilde{x}$之间的数值差异： $\Delta = \left\| \mathbf{x} - \mathbf{\tilde{x}} \right\|_2^2$

S 是输入范围与输出范围的比例： $\text{S} = \frac{\text{max} - \text{min}}{q_{\text{max}} - q_{\text{min}}}$ 

其中$[ \text{min}, \text{max} ]$是输入的裁剪范围，即允许输入的边界。 $[ q_{\text{min}}, q_{\text{max}} ]$是量化输出空间中的范围。

一般来说，裁剪范围对于量化性能有很大影响，通常需要根据实际数据分布进行**校准**，可以通过**`*静态（离线）***
或***动态（运行时）方式***`。

### 数值范围计算

- Min-Max：使用校准期间的最大绝对值；
- Histogram：将范围设置为校准期间看到的绝对值分布的百分位。
- Entropy：使用 KL 散度来最小化原始浮点值和量化比特表示的值之间的信息损失

## 量化计算


![image](https://github.com/hinswhale/AI-Learning/assets/22999866/c805eeca-13cd-4f40-8127-ff27b1a5db9f)


- q、z 都是整型计算，  S 为浮点型

将浮点数用 Q 表示法转换为定点数：

- $q_{fixed} = (int) (x_{float} * 2^Q)$
- $x_{float} = (float) (q_{fixed} * 2^{-Q})$
    
    

则两个浮点数 x1、x2 的乘法：

- $x_1*x_2 = (q_1*2^{-Q}) (q_2*2^{-Q}) = (q_1*q_2) 2^{-2Q} = ((q_1* q_2) >> Q)* 2^{-Q}$

整型的乘法(q1 * q2)和移位操作

最终只有整型的乘法(q1 * q2)和移位操作，举个例子：

- 0.234 * 0.84 = 0.19656，取 Q = 30
- 0.234 ≈ 251255586 * 2 ^-30
- 0.84 ≈ 901943132 * 2 ^-30
- 251255586 * 901943132 = 226618250169335352 (注意这里需要使用64位乘法，避免溢出)
- 226618250169335352 >> 30 = 211054692

即计算结果为： 211054692 * *2^(-30) ，转换为浮点数：211054692* * *2^(-30)*= 0.19655999913 ，

## **量化的对象**

- **权重**（weight）：量化weight可达到减少模型大小内存和占用空间。 如：W4A16、AWQ及GPTQ中的W4A16，W8A16（权重量化为INT8，激活仍为BF16或FP16）
- **激活**（activation）：**实际中activation往往是占内存使用的大头。结合权重量化一起使用，**如：SmoothQuant中的W8A8
- **KV cache**：**提高长序列生成的吞吐量**
- **梯度**（Gradients）：主要用于训练。在训练深度学习模型时，梯度通常是浮点数，它主要作用是在分布式计算中减少通信开销，同时，也可以减少backward时的开销。

## 量化策略

### 1. 均匀量化和非均匀量化

均匀量化：在量化过程中，量化函数产生的量化值之间的间距是均匀分布的。 使用更广泛

### 2. 对称量化和非对称量化

根据零点因子 𝑍 是否为零

对称量化：原始输入数据中的零点（𝑥 = 0）在量化后仍然对应到整数区间的零点

非对称量化：整数区间的零点对应到输入数值的 𝑆 · 𝑍


![image](https://github.com/hinswhale/AI-Learning/assets/22999866/ea291326-9925-4af2-8684-871470b94af2)
![image](https://github.com/hinswhale/AI-Learning/assets/22999866/06c928d7-c3c4-4339-9215-48c5329eb292)



对称量化 1. 会导致大量整型数值的浪费 2.  由于覆盖的范围更大，对称量化会引入更大的量化误差。


### 3. 线性 / 非线性

非线性：

非线性对数据分布密集的区域，给与更多的量化映射，就能增加量化后的差异性，提高精度。实际上，我们希望量化后的数据在量化空间应该均匀分布，而不是被原始数据的分布所影响。

如：分位量化方法（Quantile Quantization）

- 寻找一些分位点对原数据进行划分，使得各个区间的数据个数相等，然后将同一个区间的数据映射到同一个值，从而实现了量化
- NF4(4-bit NormalFloat Quantization) 是分位量化的一种实现

### 4. 量化粒度的选择

量化算法通常针对一个批次的数据进行处理，其中批次的规模大小就反应了量化粒度，

逐层量化（per-tensor）： 每层使用一套量化因子

逐通道（per-token & per-channel 或者 vector-wise quantization ）量化：按channel划分量化因子

逐组量化（per-group、Group-wise）：在每层中按照group使用一套量化因子

- 粒度越大，精度损失越大
- 量化粒度越小，需要额外存储的量化系数就越多

量化粒度有多种形式：

- per-tensor/per-layer
- per-channel/per-axis
- per-col/per-row
- per-embeding/per-token
- per-block/group

![image](https://github.com/hinswhale/AI-Learning/assets/22999866/bd21f71a-2f2c-49b6-be6d-64b434ef0635)

### **5. 精度选择**

**统一精度**

**混合精度**

## 量化方法

- 权重：训练完后固定，数值范围(range)与输入无关，可离线完成量化，通常相对容易量化；
- 激活：激活输出随输入变化而变化，需要统计数据动态范围，通常更难量化。范围统计的时机有两种：
    - training：训练时进行统计
    - calibration：训练后推理小批量数据进行统计


![image](https://github.com/hinswhale/AI-Learning/assets/22999866/2cd348e3-8703-4f80-871b-49d0b4ae7749)

> 量化是对每一层而言，每一层进行量化计算，每一层输出时进行反量化。下层再进行自己的量化过程
---

### **量化感知训练Quantization Aware Training（QAT）**

- 训练中调整量化误差：在网络训练过程中，模拟量化，让模型在训练过程中就能调整参数，让它更适合量化，提高量化后模型
的精度。
- 开销较大，数据要求高
- 流程：
    1. 在训练好的模型上设置权重和激活值的min-max范围的初始值，插入伪量化算子（对数值量化然后反量化），模拟量化产生的误差
    2. 在训练数据集更新权重并调整对应的量化参数(zero-point、scale)，或者直接将量化参数作为可学习的参数在反向传播中更新。
    - 简言之：训练时量化，伪量化，在线量化（在模型中添加伪量化节点模拟量化，重新训练模型（finetune），流程相对复杂）

![image](https://github.com/hinswhale/AI-Learning/assets/22999866/e026e3ad-62df-4443-9b19-9442d4352530)


![image](https://github.com/hinswhale/AI-Learning/assets/22999866/e4017120-5a01-4e67-b906-9733924cbaba)
![image](https://github.com/hinswhale/AI-Learning/assets/22999866/72e9df76-c67c-44ea-8107-a691dc84cabc)



forward pass 过程中，伪量化节点 fq 的量化是一个阶梯型的函数，而在 backward pass 中，为了反向传播能正常进行，将 fq 的梯度计算设置为直通（STE），这样在 QAT 训练中，loss 就带上了量化影响，并且能正常进行梯度下降权重更新。下图是算子 QAT 过程的流程示意图


![image](https://github.com/hinswhale/AI-Learning/assets/22999866/d12de1e8-6723-4a46-91c3-eab9edacafde)

---

### **训练后量化 Post Training Quantization （PTQ）**

> tips: 激活值中存在较大的数值
> 

- 相对简单高效，已训练好的模型 + 少量校准数据，无需重新训练模型，根据是否量化激活又分为：
#### **权重量化**
    仅量化权重，激活在推理时量化
    仅量化模型的权重以压缩模型的大小，在推理时将权重反量化为原始的float32数据，后续推理流程与普通的float32模型一致，因此推理性能不会提高
    不需要校准数据集，不需要实现量化算子，模型的精度误差较小
#### **全量化**
    模型权重 + 激活值
    在模型推理时执行量化算子来加快模型的推理速度
    需要提供一定数量的校准数据集用于统计每一层激活值的分布，并对量化后的算子做校准
    **分类：**
        - **Dynamic Quantization**  ：仅量化权重，激活值相关的量化参数是在推理阶段实时计算的，无需校准数据
        - **Static Quantization** 静态量化
            - **权重 + 模型的激活值**
            - 离线计算好模型权重和激活的量化参数，推理的时候不再调整直接使用
            - 需要一定数量的校准数据集用于统计每一层激活值的分布，并对量化后的算子做校准

> 来源：https://www.bilibili.com/video/BV1pt421w7u4
##### **Dynamic Quantization**
    - 仅量化权重，激活值相关的量化参数是在推理阶段实时计算的，无需校准数据
    - 原因： 只量化模型参数：不变，输入不固定
    - 缺点：
        - 每一次推理每一层都要对输入统计量化参数【耗时】
        - 每一层计算完成都转化成fp32，存入显存，占用显存带宽
![image](https://github.com/hinswhale/AI-Learning/assets/22999866/cb7f07d2-0574-4270-8fc5-9b06b66edd7c)


##### **Static Quantization**

    - 离线计算好模型权重和激活的量化参数，推理的时候不再调整直接使用
    - 优化点：
        - 用有代表性的输入数据跑一遍整个网络，通过统计得到每层大概得量化参数。
        - 这一层的输出是下一层的输入。下一层还是要量化，不如在这一层直接量化好再传给下一层。
    - 流程：
    
        1. 将训练好的模型权重量化为int8，并保存量化参数。
        2. 校准 (calibration）：利用一些有代表性的数据进行模型推理，用这些数据在神经网络每一层产生的激活估算出激活值的量化参数。这样就不用推理时每次根据实际激活值计算量化参数。
        3. 在每一层对量化后的int8权重和int8激活值进行计算。
        4. 在每一层输出时将结果反量化为fp32，同时根据校准产生的激活 值量化参数，把激活信量化为int8，把量化参数放入量化后的激活值中。
        5. 将lnt8的激活值和它的量化参数传入到下一层。
    

![image](https://github.com/hinswhale/AI-Learning/assets/22999866/8e7ce8a7-ceae-44bb-b44f-dd926648347a)

    
- **校正量化误差
保证量化后的分布和量化前是一致的**
___

|  | 环节 | 优缺点 | 原理 |
| --- | --- | --- | --- |
| 量化感知训练 Quantization Aware Training (QAT) | 预训练阶段 | 对模型精度要求较高 /数据要求 | 利用伪量化算子将量化带来的精度损失计入训练误差，使得优化器能在训练过程中尽量减少量化误差，得到更高的模型精度。 |
| 训练后量化 Post-training quantization (PTQ) | 推理环节 | 精度损失/ 只需要少量校准数据 |  |
|  -  动态量化 PTDQ |  | • 每一次推理每一层都要对输入统计量化参数【耗时】
• 每一层计算完成都转化成fp32，存入显存，占用显存带宽 | 仅对模型权重进行量化
推理过程中，实时计算激活的量化系数，对激活进行量化 |
| -  静态量化 |  | 静态量化更快，但对校准数据的敏感度较高 | 静态量化在推理前就计算好激活的量化系数，在推理过程中应用即可 |
| 量化感知微调（Quantization-Aware Fine-tuning，QAF） | 微调阶段 |  | 训练中优化量化误差，调整参数，从而提高模型精度 |
|  |  |  |  |
---

激活的数值范围统计：

- Min-Max
    
    直接统计最小、最大值：
    
    !https://robot9.me/wp-content/uploads/2023/12/p27.png
    
- Moving Average Min-Max
    
    增加了滑动平均，即当前的 min、max 与历史 min、max 的加权和
    
    !https://robot9.me/wp-content/uploads/2023/12/p27_2.png
    
- Histogram
    
    统计数值分布直方图，然后基于最小化量化误差或 KL 散度等算法选择合适的范围，如下图，选择 [0, 1.5] 区间就能覆盖 99% 以上的值
    
![image](https://github.com/hinswhale/AI-Learning/assets/22999866/b96c6c0a-a541-4d17-b3bf-88168c90e721)

  

# 资料
1.[模型量化-RethinkFun](https://www.bilibili.com/video/BV1pZ421J7ga)

