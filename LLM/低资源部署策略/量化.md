# Model Quantization

数据量化：

权重量化（也称为模型参数量化）和激活（值）量化，

## 量化

概念：`量化`，`反量化`，`量化误差`

将连续的输入映射到离散的输出集合。

将浮点数向量 𝒙 转化为量化值 𝒙𝒒
<img src="https://github.com/hinswhale/AI-Learning/assets/22999866/64bcda8c-5064-4663-ab28-498fce206acb" style="width: 400px; height: 150px;">

𝑆 表示缩放因子，用于确定裁剪范围

𝑍 表示零点因子，用于确定对称或非对称量化，

 𝑅(·)表示将缩放后的浮点值映射为近似整数的取整操作。

一般来说，裁剪范围对于量化性能有很大影响，通常需要根据实际数据分布进行**校准**，可以通过*`**静态（离线）***
或***动态（运行时）方式***`。

`**反量化**`（Dequantization）：从量化值中恢复原始值

<img src="https://github.com/hinswhale/AI-Learning/assets/22999866/a3f90436-e9eb-4bee-9472-20e622a791bb" style="width: 350px; height: 200px;">


`量化误差`是原始值 𝒙 和恢复值$\tilde{x}$之间的数值差异： $\Delta = \left\| \mathbf{x} - \mathbf{\tilde{x}} \right\|_2^2$

## 量化策略

### 均匀量化和非均匀量化

均匀量化：在量化过程中，量化函数产生的量化值之间的间距是均匀分布的。 使用更广泛

### 对称量化和非对称量化

根据零点因子 𝑍 是否为零

对称量化：原始输入数据中的零点（𝑥 = 0）在量化后仍然对应到整数区间的零点

非对称量化：整数区间的零点对应到输入数值的 𝑆 · 𝑍

<img src="https://github.com/hinswhale/AI-Learning/assets/22999866/d5103281-8471-409a-8413-12b33ad42db4" style="width: 400px; height: 150px;">

对称量化 1. 会导致大量整型数值的浪费 2.  由于覆盖的范围更大，对称量化会引入更大的量化误差。

### 量化粒度的选择

量化算法通常针对一个批次的数据进行处理，其中批次的规模大小就反应了量化粒度，

按张量量化：每个张量只定义一组量化参数

按通道量化

按组量化

## 量化方法

量化感知训练（Quantization-Aware Training, QAT）

训练后量化（Post-Training Quantization, PTQ）

QAT 需要更新权重

激活值中存在较大的数值

### 权重量化

逐层量化：最小化逐层的重构损失

量化权重，

优化目标：
$\arg \min_{\hat{W}} \|XW - \hat{X}\hat{W}\|_2^2$

其中 $W, \hat{W}$分别表示原始权重和量化后的权重，X为输入。

GPTQ： 逐层量化 + 权重矩阵按照列维度分组

每列参数量化后，需要适当调整组内其他未量化的参数，以弥补当前量化造成的精度损失

设计的优化方法： 延迟批次更新、 Cholesky 重构

AWQ：逐层和逐组权重量化 +  关注那些与较大激活值维度相对应的关键权重

引入针对权重的激活感知缩放策略，使得量化方法更为针对性地处理关键权重所对应的权重维度

优化目标：

$\|( \mathrm{diag}(s)^{-1} \cdot X ) \cdot Q(W \cdot \mathrm{diag}(s)) - XW \|_2^2，$

其中 Q为量化函数。通过引入缩放因子 s，

### 权重和激活值量化

细粒度量化 ：

ZeroQuant

混合精度分解：【异常值涌现现象】

将具有异常值的特征维度与其他正常维度分开计算。

<img src="https://github.com/hinswhale/AI-Learning/assets/22999866/a399df0b-f9be-4a21-a17b-d679973bbc6e" style="width: 500px; height: 550px;">

量化难度平衡

SmoothQuant

高效微调增强量化：

QLoRA： 小型可调适配器 + 用 16 比特精度进行训练与学习
