### 起源
随着模型参数、训练数据和计算资源的增加，模型性能并非线性提升，而是呈现出一种幂律关系。这个发现源于对深度学习模型性能系统性规律的探索

### 核心内容
模型性能主要受三个**核心因素**影响：  
- 模型参数数量 (Model Size)  
→ 存在递减收益效应  
- 训练数据量 (Training Data)  
→ 数据质量比数据量更重要  
→ 存在"数据饥饿"和"数据过拟合"临界点   
- 计算资源 (Compute)  
→ 训练时间和计算强度  
→ 并行计算能力  
→ 优化算法的效率  

> 经验公式可以表示为：  
> 性能 ∝ (Model Size)^α * (Training Data)^β * (Compute)^γ

**其他因素**：  
→ 模型架构  
→ 训练时间和优化算法  

### 可以做什么
- 量化模型的扩展关系：分析模型规模与性能之间的数学关系，确定是否存在某种“规律”。通过对小系统的研究，可以推断大系统的行为，或者通过简单的模型预测复杂系统的表现，寻找普适性规律
- 揭示性能瓶颈：预测模型潜在性能上限，以避免无意义的资源浪费
- 推导最佳扩展策略：指导模型架构和训练策略的优化，帮助研究者评估资源投入产出比，模型规模和资源分配

### 相关概念
- **递减收益效应**：系统性能增长并非线性，随着资源投入增加，边际收益逐渐减小，存在一个"拐点"，超过后性能提升变得不经济  
- **规模悖论**： 1/ 非线性能力跃迁 2/ 突发性涌现行为 3/ 难以提前预测的能力  

### 参考资料：
1. [大语言模型的涌现能力：现象与解释 - 张俊林](https://zhuanlan.zhihu.com/p/621438653)
