#### Time To First Token (TTFT)
➤ 首 token 延时，衡量从发送请求到生成第一个 token 所花费的时间，以毫秒为单位

#### Time Per Output Token (TPOT)
➤ 每个输出 token 的延迟（不含首个Token)

#### TPS
➤ 每秒输出token数

#### Latency
➤ 从输入到输出最后一个token所需的总时间   
Latency = TTFT+(TPOT× tokens )   
TPS = tokens / Latency   

#### Throughput
➤ 推理服务器在所有用户和请求中每秒可生成的输出词元数。    
➤ 吞吐量考虑的是系统在处理多个并发请求时的表现    


参考：
1.[常见模型提供商 API 服务性能指标](https://llmbenchmark.liduos.com/)

---
> 来源：[九原客](https://x.com/9hills/status/1808770198763360283)    

大模型推理服务的一些性能指标的换算：
1. QPS（每秒请求数，Query per Second） = VU（虚拟用户、并发用户，简称并发, Virtual User） / RT（Response Time，平均响应时间）
2. RT（平均响应时间） = TTFT（Time to First Token，首Token 延时）+ 平均输出Token 数量 / TPS（Token per Second)
3. 而 TTFT 和 平均输入 Token 数量成二次幂正相关关系，即输入越多 TTFT 越长。
4. TTFT、TPS 和单设备推理并发、模型并行数都有关系，也就是随着负载而变动。设备算力、模型结构、参数规模、输入输出长度、推理优化方法都会影响基础值。
5. 满负载、输入输出固定时，可通过压测得出 TTFT、TPS 、QPS、RT。VU 可以通过 QPS * RT 计算而来。
6. 实际聊天应用中，因为在模型响应后还有一段输入时间，所以实际聊天应用的 VU = QPS x (RT + 输入等待时间)。一般来说，将 QPS 乘以 10 为 VU。
