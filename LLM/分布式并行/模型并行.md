![image](https://github.com/user-attachments/assets/1275d99c-ca41-4b4d-a324-a4b9ab78b645)<img width="554" alt="image" src="https://github.com/user-attachments/assets/f5d41931-384f-462d-8fee-edef50e452e7"># 模型并行
![image](https://github.com/user-attachments/assets/4a7ec152-b249-439a-88fc-6d1a755e7113)

- 张量并行： 层内参数到不同设备上， 层内并行
- 流水线并行： 每层参数到同一设备上， 层间并行





## 张量并行 Tensor parallelism 
- 如何切分
- 切分后正确性
### 数学原理
A 为权重
#### 列切分

![image](https://github.com/user-attachments/assets/df366afd-34da-4f66-9e25-fceb9d3ff441)

并行策略：  
![image](https://github.com/user-attachments/assets/0176647c-da45-40b4-9a0b-969de6035542)


#### 行切分
![image](https://github.com/user-attachments/assets/7eb3962d-bb57-4aef-9fdf-ef4f96bf786c)
>  此处 X 必须按列切分  

并行策略：  
![image](https://github.com/user-attachments/assets/58a5b129-cb91-4d15-a329-2ee8b7c737a3)

Transformer: MLP：

"Y = GeLU(XA)"
![image](https://github.com/user-attachments/assets/e99bd9fd-d2aa-49a9-9f23-760de721cb32)

<img width="277" alt="image" src="https://github.com/user-attachments/assets/12c8f07c-c231-4f90-ad5a-28da3d95dcec">



### 行切分
#### Transformer: MLP：  

<img width="544" alt="image" src="https://github.com/user-attachments/assets/0c8c88af-2af7-4057-a6cf-8a9fff5311d1">


#### Transformer: Self-Attention   

<img width="554" alt="image" src="https://github.com/user-attachments/assets/8c1131cf-e110-4276-b94a-4a0f153e045a">


#### Transformer: Embedding  
![image](https://github.com/user-attachments/assets/aec24d49-40e1-4c73-8330-03b2f132763f)


𝐿=𝐿𝑜𝑠𝑠(𝑙𝑜𝑔𝑖𝑡𝑠, 𝑙𝑎𝑏𝑒𝑙𝑠)
![image](https://github.com/user-attachments/assets/cd8b8dc5-32c5-4068-be9c-0860053f3f2c)
难点： LLM 词表大, 即𝑙𝑎𝑏𝑒𝑙𝑠大 

### 列切分 


### 复制




## 流水线并行
GPipe google 和 PipeDream

tensor parallel
weight matrix （tensor）粒度
![image](https://github.com/hinswhale/AI-Learning/assets/22999866/dbc11131-6927-46c4-b470-577206900b3d)



# 资料
1. [ZOMI酱](https://www.bilibili.com/video/BV1WD4y1t7B)
