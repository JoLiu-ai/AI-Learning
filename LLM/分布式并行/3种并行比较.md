### 对比

| **特征**                | **数据并行（Data Parallelism）**                                                                 | **张量并行（Tensor Parallelism）**                                              | **流水线并行（Pipeline Parallelism）**                                           |
|-------------------------|-------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------|---------------------------------------------------------------------------------|
| **核心思想**            | **每个 GPU 存储完整模型副本**，处理不同数据批次，通过梯度同步（如 AllReduce）更新模型           | 将 **单层模型参数** 拆分到多设备（如矩阵乘法分块）                              | 将 **模型按层切分** 到多设备，通过流水线调度 micro-batches                       |
| **显存优化**            | 无显存优化，每个 GPU 存储完整模型副本（显存占用与单卡训练相同，甚至更高，需存储多份优化器状态） | 减少单设备参数存储量（如单层参数分片）                                          | 减少单设备存储的层数（如每卡仅存部分层）                                        |
| **通信开销**            | 高频中等数据量（每个 step 同步梯度，如 AllReduce）                                              | 高频小数据（每层计算需多设备通信）                                              | 低频大数据（层间传递完整激活值）                                                |
| **计算效率**            | 扩展性强，但受单卡显存限制；需高带宽 AllReduce（如 NCCL）                                      | 依赖设备间高速互联（如 NVLink）                                                 | 依赖流水线 Bubble 率优化（micro-batch 数需远大于设备数）                        |
| **典型应用**            | PyTorch DDP、DeepSpeed（结合 ZeRO）                                                             | Transformer 的注意力头或 MLP 分片（如 Megatron-LM）                            | GPipe（简单流水线）、PipeDream（1F1B 调度优化）                                 |

---

### **关键区别总结**
1. **显存优化**：
   - 数据并行：**不减少单卡显存占用**，仅通过增加 GPU 数量提升总 batch size。
   - 张量并行：**拆分单层参数**，减少单卡参数存储（适合参数密集型层，如大矩阵运算）。
   - 流水线并行：**拆分模型层数**，减少单卡存储的层数（适合层数多的模型）。

2. **通信与计算瓶颈**：
   - 数据并行：通信开销集中在梯度同步（AllReduce），需高带宽互联。
   - 张量并行：通信频繁（每层计算需设备交互），需低延迟互联（如 NVLink）。
   - 流水线并行：通信量较大（传递激活值），但频率低，需优化流水线气泡率。

3. **适用场景**：
   - **数据并行**：模型可单卡加载时，扩展训练速度的首选方案。
   - **张量并行**：单层参数超过单卡显存时（如百亿参数模型的注意力层）。
   - **流水线并行**：模型层数多且单卡无法存储所有层时（如千层 Transformer）。

---

### **协同使用场景**
在训练超大模型（如万亿参数）时，通常结合 **3D 并行**（数据+张量+流水线）：
- **DeepSpeed + Megatron-LM**：数据并行（ZeRO-3） + 张量并行（Tensor分片） + 流水线并行（层切分）。
- **通信优化**：通过分层策略（如张量并行组内 NVLink，跨组 InfiniBand）减少带宽压力。
