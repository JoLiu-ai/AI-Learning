## basic knowledge
<img width="646" alt="image" src="https://github.com/user-attachments/assets/af1b11fb-3b37-4617-b906-b9c82adae784">
![image](https://github.com/user-attachments/assets/3b81e6c5-1f8e-4629-a4df-20af9f9ef478)

ZeRO Zero Redundancy Optimizer，一系列显存优化方法的统称：
1. ZeRO-DE(PaParaled) : ZeROl/23
2. ZeRO-R (Reduce ) : Activation Checkpointing. Memory Defragmentation
3. ZeRO-Offload: Offload Strategy && Offload Schedule
4. ZeRO-Infinity : Breaking the GPU Memory Wall for Extreme Scale Deep Learning

### DeepSpeed ZeRO
- Optimizer state partitioning ( ZeRO stage 1 )
  - 只对 optimizer 状态进行切分，占内存原始1/4
- Gradient partitioning ( ZeRO stage 2 )
   - optimizer 和 grad 进行切分，占内存原始1/8
- Parameter partitioning ( ZeRO stage 3 )
    - 对optimizer、srad 和模型参数进行切分，内存减少与数据并行度和复杂度成线性关系，同时通信容量
是数据并行性的 1.5倍；

#### zero-1
- `优化器状态`(如Adam优化器中的动量和方差)在数据并行的GPU之间进行分片。每个GPU只存储和更新部分优化器状态
  - 优化器状态在显存占比最高，将优化器状态按离输出的位置关系进行分块，拆分到不同GPU上，实现零冗余
- 更新过程:
    - 在前向和反向传播时,每个GPU都有完整的模型参数副本。
    - 在参数更新阶段,每个GPU只更新自己负责的那部分参数对应的优化器状态。
    - 更新完成后,通过all-gather操作将更新后的参数同步到所有GPU上。
- 计算量：每个GPU的通信量约2*psi（梯度收集、参数广播, psi:参数量）

- 流程：
    - 在多 GPU 环境中，每个 GPU 被分配负责计算特定层的梯度。
    - 梯度计算从后向前进行(FP16)，每个 GPU 只处理自己负责的层。对于不是自己负责的层，GPU 计算自己的梯度并发送给负责该层的 GPU，由它进行汇总并计算均值。
    - 在发送梯度的同时，GPU 仍继续计算其他层的梯度。
    - 将梯度转换为 FP32 格式，用于更新一阶和二阶动量。
    - 使用更新后的动量更新成 FP32 参数。
    - 更新后的 FP32 参数转换回 FP16 格式，并广播给其他 GPU
    - 一次训练周期结束。

<img src="https://github.com/hinswhale/AI-Learning/assets/22999866/f3c4873b-e63f-438b-ad1d-418033106954)" style="width: 600px; height: 400px;">

#### zero-2
- FP16的梯度进行划分， 每个计算出最后一层的梯度，然后以桶的形式发送给负责汇总的GPU后立即释放这部分显存，反向传播完成后每个GPU都有自己负责的梯度的均值，更新自己的优化器状态及参数，然后每个GPU再把自己更新的参数广播给其他GPU
- - 计算量：每个GPU的通信量约2*psi[梯度收集：psi、参数广播：psi , psi:参数量]

#### zero-3
- 模型参数也按GPU划分，前向传播时需要其他GPU广播得到参数，处理后立即丢弃；反向传播再广播一次
- 计算量：每个GPU的通信量约3*psi，DDP的1.5倍[梯度收集：psi、参数广播（前向+反向）：2*psi , psi:参数量]


<img src="https://github.com/hinswhale/AI-Learning/assets/22999866/d617e005-20dd-4fd8-9838-f86690b30e05)" style="width: 700px; height: 400px;">
----
