
## 每个GPU存储的参数
> - **FP16 模型权重**：模型的主要参数，以 FP16 格式存储，占用较少内存。
> - **FP16 激活值**：前向传播的中间激活值以 FP16 格式存储，以节省内存。
> - **FP16 梯度**：反向传播计算得到的梯度以 FP16 格式存储。
> - **FP32 主权重副本**：虽然使用 FP16 训练，但通常会保留一份 FP32 格式的主权重副本，用于更精确的参数更新。
> - **FP32 优化器状态**：如 Adam 优化器的动量和方差等状态通常以 FP32 格式存储，以保持数值稳定性。
>   - **FP32 一阶动量 (First-order momentum)**：梯度的指数移动平均，平滑梯度更新，加速收敛
>   - **FP32 二阶动量 (Second-order momentum)**：梯度平方的指数移动平均，用于自适应调整学习率，处理梯度变化不均的情况
![image](https://github.com/hinswhale/AI-Learning/assets/22999866/c6235268-7f8a-423c-a195-2dbab36b1b22)

> 来源：https://www.bilibili.com/video/BV1mm42137X8

---
 
## 类型

-  数据并行 ：数据并行DP – 分布式数据并行 DDP – 分片共享数据并行 FSDP
-  模型并行：模型并行MP - 张量并行 TP – 流水线并行 PP
-  自动并行： MindSpore 张量自动并行
- 多维混合并行：Embedding并行 – 数据并行&模型并行 MPDP

- 数据并行 vs. 模型并行
    - 数据并行：模型拷贝（per device），数据batch 上拆分，如batch_size=32，每个device16
    - 模型并行：数据拷贝（per device），模型拆分
----

## Data parallelism

- Data parallelism, DP  单机多卡 ```nn.DataParallel```
- Distribution Data Parallel, DDP ```DistributedDataParallel```
    -  Ring-AllReduce
- Fully Sharded Data Parallel, FSDP

### DP
- 流程：cpu进程将数据分成多份给每个GPU,分别独立计算梯度，然后GPU0做汇总求均值，更新网络参数，然后将自己的参数广播出去。
- 缺点：
    - 单进程多线程运行，GIL (Global Interpreter Lock)  只能用一个cpu核[GIL使得任何时刻仅有一个线程在执行，即使在多核处理器上也是如此]
    - 0卡通信量和GPU数线性增长
    - 多卡通讯效率低，通信量与GPU成正比
### DDP
- 多进程运行，每个GPU对应的进程同时处理数据及计算梯度，通过`ring all reduce`实现梯度同步
- 👍改进点：同时发送和接收，可以最大限度利用每个显卡的上下行带宽
- 内部实现细节：
    - 模型参数按layer反序排列（输出>输入），对每个参数注册监听器，将监听器放在桶里，`多个GPU同一个桶收集满`以后再进行传输同步(降低频繁通信的开销),此时GPU同时在计算其他梯度（即`传输和计算同步进行`）
- 计算量：每个GPU的通信量约为2*psi，与GPU个数无关（scatter reduce阶段收集梯度:psi、all gather阶段分发梯度:psi, psi:参数量）
- 缺点：GPU显存限制

### DeepSpeed ZeRO
#### zero-1
- `优化器状态`(如Adam优化器中的动量和方差)在数据并行的GPU之间进行分片。每个GPU只存储和更新部分优化器状态
  - 优化器状态在显存占比最高，将优化器状态按离输出的位置关系进行分块，拆分到不同GPU上，实现零冗余
- 更新过程:
    - 在前向和反向传播时,每个GPU都有完整的模型参数副本。
    - 在参数更新阶段,每个GPU只更新自己负责的那部分参数对应的优化器状态。
    - 更新完成后,通过all-gather操作将更新后的参数同步到所有GPU上。
- 计算量：每个GPU的通信量约2*psi（梯度收集、参数广播, psi:参数量）

- 流程：
    - 在多 GPU 环境中，每个 GPU 被分配负责计算特定层的梯度。
    - 梯度计算从后向前进行(FP16)，每个 GPU 只处理自己负责的层。对于不是自己负责的层，GPU 计算自己的梯度并发送给负责该层的 GPU，由它进行汇总并计算均值。
    - 在发送梯度的同时，GPU 仍继续计算其他层的梯度。
    - 将梯度转换为 FP32 格式，用于更新一阶和二阶动量。
    - 使用更新后的动量更新成 FP32 参数。
    - 更新后的 FP32 参数转换回 FP16 格式，并广播给其他 GPU
    - 一次训练周期结束。

<img src="https://github.com/hinswhale/AI-Learning/assets/22999866/f3c4873b-e63f-438b-ad1d-418033106954)" style="width: 600px; height: 400px;">

#### zero-2
- FP16的梯度进行划分， 每个计算出最后一层的梯度，然后以桶的形式发送给负责汇总的GPU后立即释放这部分显存，反向传播完成后每个GPU都有自己负责的梯度的均值，更新自己的优化器状态及参数，然后每个GPU再把自己更新的参数广播给其他GPU
- - 计算量：每个GPU的通信量约2*psi[梯度收集：psi、参数广播：psi , psi:参数量]

#### zero-3
- 模型参数也按GPU划分，前向传播时需要其他GPU广播得到参数，处理后立即丢弃；反向传播再广播一次
- 计算量：每个GPU的通信量约3*psi，DDP的1.5倍[梯度收集：psi、参数广播（前向+反向）：2*psi , psi:参数量]


<img src="https://github.com/hinswhale/AI-Learning/assets/22999866/d617e005-20dd-4fd8-9838-f86690b30e05)" style="width: 700px; height: 400px;">
----

## 实现细节[原理+code]

### DP

```
nn.DataParallel
device_ids=None, 默认是所有gpus
output_device=None，默认gpus[0]
dim=0
The parallelized module must have its parameters and buffers on device_ids[0] before running(forward/backward) this DataParallel module.
model.to('cuda:0')
```

#### 代码
```
device = torch.device("cuda: 1,2"） ## specify the GPu id' s
model = CreateModel()
model= nn.DataParallel(model, device_ids=[1, 2])
model.to(device)
```
----
### DDP
Ring AllReduce algorithm
- 百度提出来的；
- 环形的，logical 的（逻辑的，非物理的）
- 两个过程（基于环形逻辑拓扑）
   -  scatter-reduce
   -  all gather（broadcast）

#### scatter-reduce
- 每个GPU既在发送也在接收数据
- 每个节点最后有不同的值
<img src="https://github.com/hinswhale/AI-Learning/assets/22999866/ff2c62b3-ef4a-46f8-83ea-84ced27d014f" style="width: 500px; height: 400px;">
<img src="https://github.com/hinswhale/AI-Learning/assets/22999866/6a834219-dc3d-4233-8ef3-48024bafc387" style="width: 500px; height: 400px;">
<img src="https://github.com/hinswhale/AI-Learning/assets/22999866/1f32df2c-e88c-488d-8aa1-3a41ab381333" style="width: 500px; height: 400px;">

#### all gather（broadcast）
- 每个GPU的值广播出去，与scatter-reduce是相同的(发送和接收的N-1次迭代)，只是gpu接收的值没有累加，而是简单地覆盖块
<img src="https://github.com/hinswhale/AI-Learning/assets/22999866/2b410420-5029-401e-a392-2e949958621c)" style="width: 500px; height: 400px;">
<img src="https://github.com/hinswhale/AI-Learning/assets/22999866/273820ca-ae88-47d8-b030-f6d0cc10871d)" style="width: 500px; height: 400px;">
<img src="https://github.com/hinswhale/AI-Learning/assets/22999866/e348a3fd-fa33-494a-8065-26faf623e1aa)" style="width: 500px; height: 400px;">


> 图片来源:https://www.jianshu.com/p/8c0e7edbefb9

#### ddp 相关基本概念
node, rank, world_size

![image](https://github.com/hinswhale/AI-Learning/assets/22999866/34cfe2b4-10f1-4ff8-aa9b-8c54285cad75)

----


# 资料参考
1. [ZOMI酱](https://space.bilibili.com/517221395)
2. [RethinkFun](https://www.bilibili.com/video/BV1mm42137X8)

