瓶颈：多卡间的通信
# basic 
## 可并行数据
- data
- parameters
- gradient
- optimizer

## gradient accumulation
- synchronize ： 不同GPU 处理速度不同，会有时间浪费 [更常用]
- asynchronous： 网络模型收敛困难
----
#  DP vs  DDP vs FSDP
## 1.DP (Data Parallel)
- 单进程多线程，GIL 限制
- 同步参数

## 2. DDP (Distributed Data Parallel)
- `多进程`，每个 GPU 对应一个进程
- `Ring AllReduce algorithm`
-  每个进程独立计算梯度，然后同步汇总

## 3. FSDP (Fully Sharded Data Parallel)
- shards all of model's parameters, gradients and optimizer states
- optionally offload the sharded model param pers to CPUs.

----
# 实现细节
## DDP
Ring AllReduce algorithm
- 百度提出来的；
- 环形的，logical 的（逻辑的，非物理的）
- 两个过程（基于环形逻辑拓扑）
   -  scatter-reduce
   -  all gather（broadcast）
 ![image](https://github.com/user-attachments/assets/25a3c80d-b4ad-40b8-a499-14cb61826c91)


### 具体流程
#### 1. Reduce-scatter
- 每个GPU既在发送也在接收数据
- 每个节点最后有不同的值
<img src="https://github.com/hinswhale/AI-Learning/assets/22999866/ff2c62b3-ef4a-46f8-83ea-84ced27d014f" style="width: 500px; height: 400px;">
<img src="https://github.com/hinswhale/AI-Learning/assets/22999866/6a834219-dc3d-4233-8ef3-48024bafc387" style="width: 500px; height: 400px;">
<img src="https://github.com/hinswhale/AI-Learning/assets/22999866/1f32df2c-e88c-488d-8aa1-3a41ab381333" style="width: 500px; height: 400px;">
----

#### 2. All-gather（broadcast）
- 每个GPU的值广播出去，与scatter-reduce是相同的(发送和接收的N-1次迭代)，只是gpu接收的值没有累加，而是简单地覆盖块
<img src="https://github.com/hinswhale/AI-Learning/assets/22999866/2b410420-5029-401e-a392-2e949958621c)" style="width: 500px; height: 400px;">
<img src="https://github.com/hinswhale/AI-Learning/assets/22999866/273820ca-ae88-47d8-b030-f6d0cc10871d)" style="width: 500px; height: 400px;">
<img src="https://github.com/hinswhale/AI-Learning/assets/22999866/e348a3fd-fa33-494a-8065-26faf623e1aa)" style="width: 500px; height: 400px;">


> 图片来源:https://www.jianshu.com/p/8c0e7edbefb9

### 内部实现细节
1. GPU 加载模型：GPU0 加载，再传出到其他GPU
2. 模型参数按layer反序排列（即 输出> 中间层>输入），对每个参数注册监听器（用于监听参数是否完成计算），将监听器按顺序放在桶里，
3. 多个GPU同一个桶收集满以后再进行传输同步 - 进行Ring AllReduce algorithm (降低频繁通信的开销), 此时GPU同时在计算其他梯度值（即传输和计算同步进行）
4. 每个GPU调用自己的optimizer更新网络
5. 继续下一次计算

![image](https://github.com/user-attachments/assets/aa1533c6-60fb-49bb-8778-8a2dbe6306e2)


----
## FSDP
- 工作原理:
  - 在构造函数中: 分片模型参数,每个等级只保留自己的分片
  - 在前向传播中
    - All-gather: 每个 GPU 收集所有模型参数
    - Forward: 在本地进行前向传播
    - 丢弃刚刚收集的非所有者参数分片以释放内存
  - 在反向传播中
    - All-gather: 再次收集模型参数
    - Backward: 在本地进行后向传播
    - 丢弃非所有者参数以释放内存
    - Reduce-scatter: 将梯度聚合并分片
    - Update Weight: 更新本地模型参数分片

![image](https://github.com/user-attachments/assets/9958dd2e-1bb6-4978-b1c8-60a2fd7567d2)

