
## 模型
| **模型类别**   | **模型名称**                      | **具体参数/版本**             | **语言支持** | **模型类型**   | **特点说明**                                              |
|----------------|----------------------------------|----------------------------|--------------|----------------|-----------------------------------------------------------|
| **Embedding**  | OpenAI                           | text-embedding-3-small      | English      | 商业API        | 8k上下文，MTEB英文榜62.3分，实时性要求高的问答系统               |
|                | Cohere                           | embed-english-v3.0          | English      | 商业API        | 支持search_document压缩模式                                  |
|                | BAAI                             | bge-large-en-v1.5           | English      | 开源           | 指令优化，MTEB英文榜64.2分，高精度检索、长文本处理               |
|                | Voyage                           | voyage-large-2              | English      | 商业API        | 16k上下文，金融领域优化                                      |
|                | Google                           | text-embedding-004          | 多语言       | 商业API        | 支持1024维向量                                              |
| **Reranker**   | BAAI                             | bge-reranker-large          | 中/英        | 开源           | 基于交叉熵优化，中英文双语支持，MRR@10达39.4，企业级搜索、多语言场景 |
|                | Cohere                           | rerank-english-v3.0         | English      | 商业API        | 延迟120ms，流式返回支持， 高并发在线服务                       |
|                | Sentence-Transformers            | cross-encoder/ms-marco-MiniLM-L-6 | English  | 开源           | 轻量化（60MB）                                               |
## 评估指标
### Accuracy@k（准确率@k）
$$
Accuracy@k = \frac{\text{正确预测出现在前k个结果中的次数}}{\text{总查询次数}}
$$

​场景：问答系统（如判断答案是否在前5条候选结果中）、电商推荐（商品是否在前10位曝光）

###  MAP@100（Mean Average Precision@100）

- Average Precision (AP):

$$
AP = \frac{\sum_{k=1}^{n} P@k \times rel(k)}{\text{相关结果总数}}
$$

其中 $$\( rel(k) \)$$ 表示位置 $$\( k \)$$ 的结果是否相关 $$(1/0）$$， $$\(P@k\)$$ 是前 $$\(k\)$$ 个结果的精度。
- MAP：所有查询的AP均值

- 典型场景：
大规模文档检索（如搜索引擎评估前100页结果质量）

```python
# 查询1的相关文档位置为[3,5,9]，前100个结果中：
P@3 = 1/3, P@5 = 2/5, P@9 = 3/9
AP = (1/3 + 2/5 + 3/9)/3 ≈ 0.311
# 查询2的AP为0.45 → MAP = (0.311 + 0.45)/2 = 0.3805
```

### MRR@10（Mean Reciprocal Rank@10）
- Reciprocal Rank (RR)：

$$
RR = \frac{1}{\text{第一个正确答案的位置}} \quad (\text{若位置} > 10 \text{ 则 } RR = 0)
$$

- MRR：所有查询的RR均值
- 典型场景：
  问答机器人（关注第一个正确答案的位置）、客服系统（快速定位解决方案）

```python
# 查询1的第一个正确答案在位置3 → RR = 1/3
# 查询2的第一个正确答案在位置12 → RR = 0（因仅看前10）
MRR = (1/3 + 0)/2 ≈ 0.1667
```

### NDCG@10（Normalized Discounted Cumulative Gain@10）
- **DCG（折损累积增益）：**

$$
DCG@k = \sum_{i=1}^{k} \frac{rel_i}{\log_2(i+1)}
$$

其中 \( rel_i \) 为位置 \( i \) 的结果相关性（如3级：2=强相关，1=弱相关，0=无关）

- **IDCG:** 理想排序下的DCG值

- **NDCG:**

$$
NDCG@k = \frac{DCG@k}{IDCG@k}
$$


- **典型场景:**
多级相关性排序（如新闻推荐中区分"点击"、"长阅读"、"分享"等级别）

```python
# 实际相关性排序：[3,2,3,1]（假设最高级为3）
# 系统返回的相关性得分：[3,1,2,0]
DCG = 3 + 1/log2(3) + 2/log2(4) ≈ 3 + 0.63 + 1 = 4.63
IDCG = 3 + 3/log2(3) + 2/log2(4) + 1/log2(5) ≈ 3 + 1.89 + 1 + 0.43 = 6.32
NDCG@4 = 4.63 / 6.32 ≈ 0.733
```

| **指标**      | **侧重点**                   | **适用场景**                         | **局限性**                       |
|---------------|----------------------------|-------------------------------------|---------------------------------|
| Accuracy@k    | 是否存在正确答案             | 快速验证基础召回能力                  | 忽略排序质量，无法区分位置         |
| MAP@100       | 前100位的平均精度            | 需要平衡召回与排序的综合评估         | 计算复杂度高，需明确相关性        |
| MRR@10        | 首个正确答案的位置           | 强调快速定位正确答案的时效性         | 对后续正确答案不敏感              |
| NDCG@10       | 多级相关性的排序质量         | 精细化评估推荐/检索系统的用户体验     | 需人工标注多级相关性标签         |


## 榜单
todolist
