## 1. 检索Retrieve环节
### 指标
* Hit Rate 命中率
	前k项中，包含正确信息的项的数目占比
	一般，Hit Rate越高，就说明召回算法效果越好。
* MRR[Mean Reciprocal Rank]平均倒排率
	查询（或推荐请求）的排名倒数
	一种常见的评估检索效果的指标。衡量系统在一系列查询中返回相关文档或信息的平均排名的逆数的平均值

如果一个系统对第一个查询的正确答案排在第二位，对第二个查询的正确答案排在第一位，则 MRR 为 (1/2 + 1/1) / 2。
* NDCG
### 评估示例
https://blog.llamaindex.ai/boosting-rag-picking-the-best-embedding-reranker-models-42d079022e83
### 步骤
1. 文档划分：寻找合适数据集，进行文档划分；
2. 问题生成：对划分后的文档，使用 LLM 对文档内容生成问题；
3. 召回文本：对生成的每个问题，采用不同的 Retrieve 算法，得到召回结果；
4. 指标评估：使用Hit Rate和MRR指标进行评估
   
## 2. 向量模型
###  指标
一般向量模型的训练都是基于分类的训练策略，所以其本身的评估也可以考虑准确率召回率。
### 评估示例

## 3.大模型的文本生成环节
### 指标
* 非量化：完整性、正确性、相关性
* 量化：Rouge-L
### 评估示例
