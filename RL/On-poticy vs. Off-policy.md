## On-policy（同策略）
### 核心特点

- `策略与数据生成一致`：使用当前策略（目标策略）直接与环境交互并生成数据，边学习边更新策略。
- `数据利用率低`：每次策略更新后，旧数据因策略变化而被丢弃，必须重新采样，导致样本效率低。

### 典型算法
A3C、PPO（近端策略优化）、TRPO（信赖域策略优化）



## Off-policy（异策略）
### 核心特点

- `策略与数据生成分离`：使用行为策略（如ε-greedy）生成数据，目标策略（如贪婪策略）从中学习。
- `数据利用率高`：可重复利用历史数据（如经验回放），提升样本效率。

### 典型算法
Q-learning、DDPG、TD3、SAC。
