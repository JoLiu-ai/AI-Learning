# NormalFloat4- NF4

> NF4 符合正态分布的数据做int4量化，量化后没有办法进行直接计算，只能反量化为`浮点型`进行计算

##  非线性量化 vs 线性量化
线性量化：均匀分布
非线性量化：正态分布中0点附近密集，两边分布稀疏

## 思想
* 背景：一般参数值符合均值为0的正态分布，0附近值很多，两边很少，密度大的地方分配值多一些，其他地方少一些，均匀分布会浪费
* 思路：非线性对数据分布密集的区域，给予更多的量化映射，就能增加量化后的差异性，提高精度。实际上，我们希望量化后的数据在量化空间应该均匀分布，而不是被原始数据的分布所影响。

## 量化 & 反量化
量化：找到映射区间中最接近的值
![image](https://github.com/hinswhale/AI-Learning/assets/22999866/ec4a97ef-8e7f-4b9b-b5e6-ac49bf690ac7)

反量化： 找到对应区间，区间内最大值+最小值取均值
![image](https://github.com/hinswhale/AI-Learning/assets/22999866/812f9d19-7b8c-4407-b940-6c1e519a2409)

## 问题：
  - 正态分布值(-∞，+∞)， 反量化时没法求最后区间均值
      - 解决方法：两边舍弃累计概率密度
  - 0 值：反量化后不再是0，需做特殊处理
      - 解决方法：单独拿出来，0（1bit）正数(8), 负数(7)

## 流程

1.根据上述规则，制作映射表格（0（1bit）正数(8), 负数(7)）

2.量化流程：
  - 归一化， 每个数/ 最大值绝对值，scale 需要保存
  - 查表，和哪个值接近，就取对应的值

3.反量化流程：
  - 查表 ， 跟scale相乘

![image](https://github.com/hinswhale/AI-Learning/assets/22999866/7e01c391-1559-41ac-8047-5dc23d763799)


应用：QLoRA

## QLoRA

- QLORA里每64个值作为一个块进行NF4 4-bit量化。

- 分块量化带来的问题

  - 64个4bit = 256 bit
  - 1个32位的scale， 额外占用：32/256 = 12.5%

- 解决办法： 双重量化
  - 每256个分块的scale值进行一次8bit量化。 （额外占用从12.5%降低到3.174%）
  - `双重量化减少了显存占用，但是反量化时要进行两次反量化，先对scale值进行反量化，然后对tensor值进行反量化。`

NF4量化后没有办法进行直接计算，只能反量化为`浮点型`进行计算，需要制定compute type

# 参考
1.[RethinkFun](https://space.bilibili.com/18235884)
